{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37048780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Ensemble: Weighted Boxes Fusion (WBF) y evaluación en test, test2, test3 ===\n",
    "# Requiere: pip install ensemble-boxes (solo para WBF)\n",
    "\n",
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ultralytics import YOLO\n",
    "from lib.YOLO_lib import config\n",
    "\n",
    "try:\n",
    "    from ensemble_boxes import weighted_boxes_fusion\n",
    "    HAS_WBF = True\n",
    "except ImportError:\n",
    "    HAS_WBF = False\n",
    "    print(\"Instala ensemble-boxes para WBF: pip install ensemble-boxes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "164aa4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_model_paths = {\n",
    "    \"yolov12s\": config.final_model_path[\"yolov12s\"],\n",
    "    \"yolov11s\": config.final_model_path[\"yolov11s\"],\n",
    "    \"yolov10s\":  config.final_model_path[\"yolov8s\"],\n",
    "}\n",
    "\n",
    "base_models = {k: YOLO(p) for k,p in ensemble_model_paths.items()}\n",
    "\n",
    "model_weights = {\n",
    "    \"yolov12s\": 0.6,\n",
    "    \"yolov11s\": 0.1,\n",
    "    \"yolov10s\":  0.3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "343106e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilidades\n",
    "def load_yolo_labels(label_file):\n",
    "    boxes = []\n",
    "    if not os.path.exists(label_file):\n",
    "        return np.zeros((0,5), dtype=float)\n",
    "    with open(label_file, \"r\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) != 5:\n",
    "                continue\n",
    "            cls, x, y, w, h = map(float, parts)\n",
    "            boxes.append([cls, x, y, w, h])\n",
    "    return np.array(boxes, dtype=float) if boxes else np.zeros((0,5), dtype=float)\n",
    "\n",
    "\n",
    "def yolo_to_xyxy_norm(boxes):\n",
    "    # boxes: (N,5) cls, cx, cy, w, h (normalizado)\n",
    "    if boxes.size == 0:\n",
    "        return boxes[:, :0]\n",
    "    cx, cy, w, h = boxes[:,1], boxes[:,2], boxes[:,3], boxes[:,4]\n",
    "    x1 = cx - w/2\n",
    "    y1 = cy - h/2\n",
    "    x2 = cx + w/2\n",
    "    y2 = cy + h/2\n",
    "    return np.stack([x1,y1,x2,y2], axis=1)\n",
    "\n",
    "\n",
    "def iou_matrix(a, b):\n",
    "    # a,b: (N,4) (M,4) en formato xyxy normalizado\n",
    "    if a.size == 0 or b.size == 0:\n",
    "        return np.zeros((len(a), len(b)), dtype=float)\n",
    "    ious = np.zeros((len(a), len(b)), dtype=float)\n",
    "    for i, box_a in enumerate(a):\n",
    "        ax1, ay1, ax2, ay2 = box_a\n",
    "        aarea = max(0, ax2-ax1) * max(0, ay2-ay1)\n",
    "        for j, box_b in enumerate(b):\n",
    "            bx1, by1, bx2, by2 = box_b\n",
    "            barea = max(0, bx2-bx1) * max(0, by2-by1)\n",
    "            ix1 = max(ax1, bx1)\n",
    "            iy1 = max(ay1, by1)\n",
    "            ix2 = min(ax2, bx2)\n",
    "            iy2 = min(ay2, by2)\n",
    "            iw = max(0, ix2-ix1)\n",
    "            ih = max(0, iy2-iy1)\n",
    "            inter = iw * ih\n",
    "            union = aarea + barea - inter\n",
    "            ious[i,j] = inter / union if union > 0 else 0.0\n",
    "    return ious\n",
    "\n",
    "\n",
    "def predict_single_model(model, image_path, imgsz):\n",
    "    r = model.predict(image_path, imgsz=imgsz, conf=0.001, verbose=False)[0]\n",
    "    h, w = r.orig_shape\n",
    "    if r.boxes.shape[0] == 0:\n",
    "        return {\"boxes\": np.zeros((0,4)), \"conf\": np.zeros((0,)), \"cls\": np.zeros((0,))}\n",
    "    xyxy = r.boxes.xyxy.cpu().numpy()\n",
    "    conf = r.boxes.conf.cpu().numpy()\n",
    "    cls = r.boxes.cls.cpu().numpy()\n",
    "    # Normalizar\n",
    "    xyxy_norm = xyxy.copy()\n",
    "    xyxy_norm[:,[0,2]] /= w\n",
    "    xyxy_norm[:,[1,3]] /= h\n",
    "    return {\"boxes\": xyxy_norm, \"conf\": conf, \"cls\": cls}\n",
    "\n",
    "\n",
    "def ensemble_wbf(image_path, imgsz=704, iou_thr=0.9, skip_box_thr=0.5):\n",
    "    if not HAS_WBF:\n",
    "        return np.zeros((0,6)), 0\n",
    "    \n",
    "    start_time = time.time()\n",
    "    boxes_list, scores_list, labels_list, weights = [], [], [], []\n",
    "    \n",
    "    for name, m in base_models.items():\n",
    "        r = predict_single_model(m, image_path, imgsz)\n",
    "        \n",
    "        boxes_list.append(r[\"boxes\"].tolist())\n",
    "        scores_list.append(r[\"conf\"].tolist())\n",
    "        labels_list.append(r[\"cls\"].astype(int).tolist())\n",
    "        weights.append(model_weights[name])\n",
    "    \n",
    "    if sum(len(b) for b in boxes_list) == 0:\n",
    "        return np.zeros((0,6)), (time.time() - start_time) * 1000\n",
    "        \n",
    "    fused_boxes, fused_scores, fused_labels = weighted_boxes_fusion(\n",
    "        boxes_list, scores_list, labels_list,\n",
    "        weights=weights, iou_thr=iou_thr, skip_box_thr=skip_box_thr\n",
    "    )\n",
    "    \n",
    "    fused_boxes = np.array(fused_boxes)\n",
    "    fused_scores = np.array(fused_scores)\n",
    "    fused_labels = np.array(fused_labels)\n",
    "    \n",
    "    dets = np.concatenate([fused_boxes, fused_scores[:,None], fused_labels[:,None]], axis=1)\n",
    "    inference_time = (time.time() - start_time) * 1000  # ms\n",
    "    \n",
    "    return dets, inference_time\n",
    "\n",
    "# Métricas (AP@0.5 y AP@[0.5:0.95], precisión y recall global)\n",
    "def compute_metrics(preds_all, gts_all, iou_thresholds=None):\n",
    "    # preds_all & gts_all: listas por imagen\n",
    "    if iou_thresholds is None:\n",
    "        iou_thresholds = np.arange(0.5, 1.0, 0.05)  # [0.5, 0.55, ..., 0.95]\n",
    "    \n",
    "    # Para precisión/recall global a IoU=0.5 (primera)\n",
    "    iou_main = iou_thresholds[0]\n",
    "    \n",
    "    num_classes = 1\n",
    "    \n",
    "    class_APs = np.zeros((num_classes, len(iou_thresholds)))\n",
    "    \n",
    "    # Para cada clase (solo tenemos una pero mantenemos la estructura)\n",
    "    for class_id in range(num_classes):\n",
    "        for t_idx, t in enumerate(iou_thresholds):\n",
    "            # Recolectar todas las predicciones y sus etiquetas TP/FP\n",
    "            all_pred_entries = []\n",
    "            total_gts = 0\n",
    "            \n",
    "            # Procesar cada imagen\n",
    "            for preds, gts in zip(preds_all, gts_all):\n",
    "                total_gts += gts.shape[0]\n",
    "                if preds.shape[0] == 0:\n",
    "                    continue\n",
    "                \n",
    "                # Filtrar predicciones de esta clase (si tuviéramos múltiples)\n",
    "                # preds_class = preds[preds[:,5] == class_id]\n",
    "                preds_class = preds  # Todas son de la misma clase\n",
    "                \n",
    "                if preds_class.shape[0] == 0:\n",
    "                    continue\n",
    "                \n",
    "                # Ordenar por score\n",
    "                order = np.argsort(-preds_class[:,4])\n",
    "                p = preds_class[order]\n",
    "                \n",
    "                # Marcar TP/FP\n",
    "                matched = np.zeros(gts.shape[0], dtype=bool)\n",
    "                for row in p:\n",
    "                    box_p = row[:4][None,:]\n",
    "                    ious = iou_matrix(box_p, gts)\n",
    "                    best_i = np.argmax(ious[0]) if gts.shape[0] else -1\n",
    "                    best_iou = ious[0,best_i] if gts.shape[0] else 0\n",
    "                    is_tp = best_iou >= t and (best_i >=0) and (not matched[best_i])\n",
    "                    if is_tp:\n",
    "                        matched[best_i] = True\n",
    "                    all_pred_entries.append((row[4], 1 if is_tp else 0))\n",
    "            \n",
    "            # Si no hay GT o predicciones, AP=0\n",
    "            if total_gts == 0 or not all_pred_entries:\n",
    "                class_APs[class_id, t_idx] = 0.0\n",
    "                continue\n",
    "            \n",
    "            # Ordenar predicciones por confianza (mayor a menor)\n",
    "            all_pred_entries.sort(key=lambda x: -x[0])\n",
    "            \n",
    "            # Calcular precisión y recall acumulados\n",
    "            cum_tp = 0\n",
    "            cum_fp = 0\n",
    "            precisions = []\n",
    "            recalls = []\n",
    "            \n",
    "            for _, is_tp in all_pred_entries:\n",
    "                if is_tp:\n",
    "                    cum_tp += 1\n",
    "                else:\n",
    "                    cum_fp += 1\n",
    "                precisions.append(cum_tp / (cum_tp + cum_fp))\n",
    "                recalls.append(cum_tp / total_gts)\n",
    "            \n",
    "            # Convertir a arrays para procesamiento\n",
    "            precisions = np.array(precisions)\n",
    "            recalls = np.array(recalls)\n",
    "            \n",
    "            # Interpolación COCO: asegurar monotonicidad descendente (máximo a la derecha)\n",
    "            for i in range(len(precisions)-2, -1, -1):\n",
    "                precisions[i] = max(precisions[i], precisions[i+1])\n",
    "            \n",
    "            # Método COCO: interpolar en 101 puntos de recall [0, 0.01, 0.02, ..., 1.0]\n",
    "            ap = 0.0\n",
    "            for r in np.linspace(0, 1, 101):\n",
    "                # Encontrar la precisión máxima para recall >= r\n",
    "                prec = 0.0\n",
    "                for i in range(len(recalls)):\n",
    "                    if recalls[i] >= r:\n",
    "                        prec = max(prec, precisions[i])\n",
    "                ap += prec / 101.0\n",
    "            \n",
    "            # Asignar AP para esta clase y umbral IoU\n",
    "            class_APs[class_id, t_idx] = ap\n",
    "    \n",
    "    # Calcular estadísticas globales a IoU=0.5\n",
    "    tp_main = 0\n",
    "    fp_main = 0\n",
    "    \n",
    "    for preds, gts in zip(preds_all, gts_all):\n",
    "        if preds.shape[0] == 0:\n",
    "            tp_main += 0\n",
    "            fp_main += 0\n",
    "            continue\n",
    "        \n",
    "        # Ordenar por score\n",
    "        order = np.argsort(-preds[:,4])\n",
    "        p = preds[order]\n",
    "        \n",
    "        # Marcar TP/FP para IoU=0.5\n",
    "        matched = np.zeros(gts.shape[0], dtype=bool)\n",
    "        for row in p:\n",
    "            box_p = row[:4][None,:]\n",
    "            ious = iou_matrix(box_p, gts)\n",
    "            best_i = np.argmax(ious[0]) if gts.shape[0] else -1\n",
    "            best_iou = ious[0,best_i] if gts.shape[0] else 0\n",
    "            \n",
    "            if best_iou >= iou_main and best_i >=0 and (not matched[best_i]):\n",
    "                matched[best_i] = True\n",
    "                tp_main += 1\n",
    "            else:\n",
    "                fp_main += 1\n",
    "    \n",
    "    fn_main = sum(gt.shape[0] for gt in gts_all) - tp_main\n",
    "    mp = tp_main / (tp_main + fp_main) if (tp_main + fp_main) > 0 else 0.0\n",
    "    mr = tp_main / (tp_main + fn_main) if (tp_main + fn_main) > 0 else 0.0\n",
    "    \n",
    "    # Calcular mAP@0.5 y mAP@[0.5:0.95] según COCO\n",
    "    map50 = np.mean(class_APs[:, 0])  # Primera columna = IoU 0.5\n",
    "    map5095 = np.mean(class_APs)       # Media de todas las IoUs\n",
    "    \n",
    "    return {\n",
    "        \"mp\": mp,\n",
    "        \"mr\": mr,\n",
    "        \"map50\": map50,\n",
    "        \"map\": map5095\n",
    "    }\n",
    "\n",
    "\n",
    "def get_split_image_label_dirs(split_name):\n",
    "    base = Path(\"..\") / \"03.Datasets\" / \"YOLO_Datasets\"\n",
    "    images = base / split_name / \"images\"\n",
    "    labels = base / split_name / \"labels\"\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "def evaluate_ensemble(split, method=\"wbf\", imgsz=config.IMGSZ):\n",
    "    img_dir, label_dir = get_split_image_label_dirs(split)\n",
    "    image_paths = [p for p in img_dir.iterdir() if p.suffix.lower() in [\".jpg\", \".png\", \".jpeg\"]]\n",
    "    preds_all = []\n",
    "    gts_all = []\n",
    "    inference_times = []\n",
    "    \n",
    "    for img_path in image_paths:\n",
    "        # Ground truth\n",
    "        gt_label = (label_dir / (img_path.stem + \".txt\"))\n",
    "        gts_raw = load_yolo_labels(str(gt_label))  # cls, cx, cy, w, h\n",
    "        gts_xyxy = yolo_to_xyxy_norm(gts_raw) if gts_raw.size else np.zeros((0,4))\n",
    "        gts_all.append(gts_xyxy)\n",
    "\n",
    "        dets, inf_time = ensemble_wbf(str(img_path), imgsz=imgsz, iou_thr=0.50, skip_box_thr=0.3)\n",
    "        inference_times.append(inf_time)\n",
    "        # dets: (N,6) xyxy + conf + cls\n",
    "        preds_all.append(dets if dets.size else np.zeros((0,6)))\n",
    "        \n",
    "    metrics = compute_metrics(preds_all, gts_all)\n",
    "    # Añadir tiempo de inferencia promedio a las métricas\n",
    "    metrics[\"inference_time\"] = np.mean(inference_times)\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39ea5f71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Test</th>\n",
       "      <th>Precisión</th>\n",
       "      <th>Recall</th>\n",
       "      <th>mAP@0.5</th>\n",
       "      <th>mAP@0.5:0.95</th>\n",
       "      <th>Inferencia (ms)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ensemble_wbf</td>\n",
       "      <td>test_original</td>\n",
       "      <td>0.780227</td>\n",
       "      <td>0.917518</td>\n",
       "      <td>0.882009</td>\n",
       "      <td>0.716803</td>\n",
       "      <td>112.061919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ensemble_wbf</td>\n",
       "      <td>test</td>\n",
       "      <td>0.838343</td>\n",
       "      <td>0.888810</td>\n",
       "      <td>0.859278</td>\n",
       "      <td>0.684976</td>\n",
       "      <td>105.827329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ensemble_wbf</td>\n",
       "      <td>test2</td>\n",
       "      <td>0.895425</td>\n",
       "      <td>0.951389</td>\n",
       "      <td>0.944046</td>\n",
       "      <td>0.486713</td>\n",
       "      <td>75.143909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ensemble_wbf</td>\n",
       "      <td>test3</td>\n",
       "      <td>0.832524</td>\n",
       "      <td>0.906608</td>\n",
       "      <td>0.877287</td>\n",
       "      <td>0.702190</td>\n",
       "      <td>93.946530</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Modelo           Test  Precisión    Recall   mAP@0.5  mAP@0.5:0.95  \\\n",
       "0  ensemble_wbf  test_original   0.780227  0.917518  0.882009      0.716803   \n",
       "1  ensemble_wbf           test   0.838343  0.888810  0.859278      0.684976   \n",
       "2  ensemble_wbf          test2   0.895425  0.951389  0.944046      0.486713   \n",
       "3  ensemble_wbf          test3   0.832524  0.906608  0.877287      0.702190   \n",
       "\n",
       "   Inferencia (ms)  \n",
       "0       112.061919  \n",
       "1       105.827329  \n",
       "2        75.143909  \n",
       "3        93.946530  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_splits = [\"test_original\",\"test\",\"test2\",\"test3\"]\n",
    "ensemble_results = []\n",
    "for split in test_splits:\n",
    "    m2 = evaluate_ensemble(split, method=\"wbf\")\n",
    "    ensemble_results.append({\n",
    "        \"Modelo\": \"ensemble_wbf\",\n",
    "        \"Test\": split,\n",
    "        \"Precisión\": m2[\"mp\"],\n",
    "        \"Recall\": m2[\"mr\"],\n",
    "        \"mAP@0.5\": m2[\"map50\"],\n",
    "        \"mAP@0.5:0.95\": m2[\"map\"],\n",
    "        \"Inferencia (ms)\": m2[\"inference_time\"]\n",
    "    })\n",
    "\n",
    "df_ensemble = pd.DataFrame(ensemble_results)\n",
    "display(df_ensemble)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TFM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
