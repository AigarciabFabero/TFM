{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1948171",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn_v2, FasterRCNN_ResNet50_FPN_V2_Weights\n",
    "from torchvision.transforms import functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2ea6418",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_NAMES=[\"background\", \"defectCell\"]\n",
    "\n",
    "class ConsensusEnsemble:\n",
    "    def __init__(self, fast_rcnn_path, yolo_path, device='cuda'):\n",
    "        self.device = torch.device(device)\n",
    "        self.fast_rcnn = self.load_fast_rcnn(fast_rcnn_path)\n",
    "        self.yolo = YOLO(yolo_path)\n",
    "        \n",
    "        # Parámetros de consenso\n",
    "        self.consensus_iou_threshold = 0.6\n",
    "        self.min_confidence = 0.7\n",
    "        \n",
    "    def load_fast_rcnn(self, model_path):\n",
    "        \"\"\"Carga el modelo Fast-RCNN\"\"\"\n",
    "        weights = FasterRCNN_ResNet50_FPN_V2_Weights.DEFAULT\n",
    "        model = fasterrcnn_resnet50_fpn_v2(weights=weights)\n",
    "        \n",
    "        in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "        model.roi_heads.box_predictor = FastRCNNPredictor(in_features, len(CLASS_NAMES))\n",
    "        \n",
    "        model.load_state_dict(torch.load(model_path, map_location=self.device))\n",
    "        model.to(self.device)\n",
    "        model.eval()\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def predict_fast_rcnn(self, image_path, conf_threshold=0.4):\n",
    "        \"\"\"Predicción con Fast-RCNN\"\"\"\n",
    "        img = torchvision.io.read_image(image_path)\n",
    "        img = img.float() / 255.0\n",
    "        img_tensor = img.unsqueeze(0).to(self.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            predictions = self.fast_rcnn(img_tensor)[0]\n",
    "        \n",
    "        keep = predictions['scores'] > conf_threshold\n",
    "        \n",
    "        return {\n",
    "            'boxes': predictions['boxes'][keep].cpu().numpy().tolist(),\n",
    "            'scores': predictions['scores'][keep].cpu().numpy().tolist(),\n",
    "            'labels': predictions['labels'][keep].cpu().numpy().tolist()\n",
    "        }\n",
    "    \n",
    "    def predict_yolo(self, image_path, conf_threshold=0.4):\n",
    "        \"\"\"Predicción con YOLO\"\"\"\n",
    "        results = self.yolo(image_path, conf=conf_threshold)\n",
    "        \n",
    "        if len(results[0].boxes) > 0:\n",
    "            boxes = results[0].boxes.xyxy.cpu().numpy().tolist()\n",
    "            scores = results[0].boxes.conf.cpu().numpy().tolist()\n",
    "            # Convertir etiquetas YOLO a formato Fast-RCNN (YOLO: 0=defectCell -> Fast-RCNN: 1=defectCell)\n",
    "            labels = (results[0].boxes.cls.cpu().numpy() + 1).tolist()\n",
    "        else:\n",
    "            boxes, scores, labels = [], [], []\n",
    "        \n",
    "        return {'boxes': boxes, 'scores': scores, 'labels': labels}\n",
    "    \n",
    "    def calculate_iou(self, box1, box2):\n",
    "        \"\"\"Calcula IoU entre dos cajas\"\"\"\n",
    "        x1 = max(box1[0], box2[0])\n",
    "        y1 = max(box1[1], box2[1])\n",
    "        x2 = min(box1[2], box2[2])\n",
    "        y2 = min(box1[3], box2[3])\n",
    "        \n",
    "        if x2 <= x1 or y2 <= y1:\n",
    "            return 0.0\n",
    "        \n",
    "        intersection = (x2 - x1) * (y2 - y1)\n",
    "        area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "        area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "        union = area1 + area2 - intersection\n",
    "        \n",
    "        return intersection / union if union > 0 else 0.0\n",
    "    \n",
    "    def find_consensus(self, fast_rcnn_pred, yolo_pred):\n",
    "        \"\"\"\n",
    "        Encuentra detecciones con consenso entre ambos modelos\n",
    "        Solo mantiene detecciones que ambos modelos detectan\n",
    "        \"\"\"\n",
    "        if not fast_rcnn_pred['boxes'] or not yolo_pred['boxes']:\n",
    "            return {'boxes': [], 'scores': [], 'labels': []}\n",
    "        \n",
    "        consensus_results = {'boxes': [], 'scores': [], 'labels': []}\n",
    "        \n",
    "        # Para cada detección de Fast-RCNN, buscar consenso en YOLO\n",
    "        for i, box1 in enumerate(fast_rcnn_pred['boxes']):\n",
    "            label1 = fast_rcnn_pred['labels'][i]\n",
    "            score1 = fast_rcnn_pred['scores'][i]\n",
    "            \n",
    "            best_iou = 0\n",
    "            best_match_idx = -1\n",
    "            \n",
    "            # Buscar la mejor coincidencia en YOLO\n",
    "            for j, box2 in enumerate(yolo_pred['boxes']):\n",
    "                label2 = yolo_pred['labels'][j]\n",
    "                \n",
    "                if label1 == label2:  # Misma clase\n",
    "                    iou = self.calculate_iou(box1, box2)\n",
    "                    if iou > best_iou and iou > self.consensus_iou_threshold:\n",
    "                        best_iou = iou\n",
    "                        best_match_idx = j\n",
    "            \n",
    "            # Si hay consenso suficiente, agregar detección\n",
    "            if best_match_idx >= 0:\n",
    "                box2 = yolo_pred['boxes'][best_match_idx]\n",
    "                score2 = yolo_pred['scores'][best_match_idx]\n",
    "                \n",
    "                # Promediar coordenadas y scores\n",
    "                avg_box = [(box1[k] + box2[k]) / 2 for k in range(4)]\n",
    "                avg_score = (score1 + score2) / 2\n",
    "                \n",
    "                # Solo agregar si la confianza promedio es suficientemente alta\n",
    "                if avg_score >= self.min_confidence:\n",
    "                    consensus_results['boxes'].append(avg_box)\n",
    "                    consensus_results['scores'].append(avg_score)\n",
    "                    consensus_results['labels'].append(label1)\n",
    "        \n",
    "        return consensus_results\n",
    "    \n",
    "    def predict(self, image_path):\n",
    "        \"\"\"\n",
    "        Predicción principal usando consenso\n",
    "        \"\"\"\n",
    "        # Obtener predicciones de ambos modelos\n",
    "        fast_rcnn_pred = self.predict_fast_rcnn(image_path)\n",
    "        yolo_pred = self.predict_yolo(image_path)\n",
    "        \n",
    "        print(f\"Fast-RCNN: {len(fast_rcnn_pred['boxes'])} detecciones\")\n",
    "        print(f\"YOLO: {len(yolo_pred['boxes'])} detecciones\")\n",
    "        \n",
    "        # Encontrar consenso\n",
    "        consensus_result = self.find_consensus(fast_rcnn_pred, yolo_pred)\n",
    "        \n",
    "        print(f\"Consenso: {len(consensus_result['boxes'])} detecciones\")\n",
    "        \n",
    "        return consensus_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dcc32ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConsensusEnsembleEvaluator:\n",
    "    def __init__(self, consensus_ensemble, output_dir=\"./ensemble_evaluation\"):\n",
    "        self.ensemble = consensus_ensemble\n",
    "        self.output_dir = output_dir\n",
    "        self.create_output_dirs()\n",
    "        \n",
    "        # Métricas acumuladas\n",
    "        self.all_predictions = []\n",
    "        self.all_ground_truth = []\n",
    "        self.detection_metrics = {\n",
    "            'true_positives': 0,\n",
    "            'false_positives': 0, \n",
    "            'false_negatives': 0,\n",
    "            'total_predictions': 0,\n",
    "            'total_ground_truth': 0\n",
    "        }\n",
    "        \n",
    "    def create_output_dirs(self):\n",
    "        \"\"\"Crear directorios de salida\"\"\"\n",
    "        os.makedirs(self.output_dir, exist_ok=True)\n",
    "        os.makedirs(os.path.join(self.output_dir, \"visualizations\"), exist_ok=True)\n",
    "        os.makedirs(os.path.join(self.output_dir, \"metrics\"), exist_ok=True)\n",
    "        os.makedirs(os.path.join(self.output_dir, \"results\"), exist_ok=True)\n",
    "        \n",
    "    def evaluate_test_set(self, test_images_dir, test_labels_dir=None, \n",
    "                         iou_threshold=0.5, save_visualizations=True):\n",
    "        \"\"\"\n",
    "        Evalúa todo el conjunto de test\n",
    "        \n",
    "        Args:\n",
    "            test_images_dir: Directorio con imágenes de test\n",
    "            test_labels_dir: Directorio con labels YOLO (.txt)\n",
    "            iou_threshold: Umbral IoU para considerar TP\n",
    "            save_visualizations: Si guardar imágenes con boxes\n",
    "        \"\"\"\n",
    "        print(f\"🚀 Iniciando evaluación del conjunto de test...\")\n",
    "        print(f\"📁 Directorio de imágenes: {test_images_dir}\")\n",
    "        print(f\"📁 Directorio de salida: {self.output_dir}\")\n",
    "        \n",
    "        # Obtener lista de imágenes\n",
    "        image_files = [f for f in os.listdir(test_images_dir) \n",
    "                      if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "        \n",
    "        print(f\"📊 Total de imágenes a evaluar: {len(image_files)}\")\n",
    "        \n",
    "        results_data = []\n",
    "        \n",
    "        for i, image_file in enumerate(image_files):\n",
    "            print(f\"🔍 Procesando {i+1}/{len(image_files)}: {image_file}\")\n",
    "            \n",
    "            image_path = os.path.join(test_images_dir, image_file)\n",
    "            \n",
    "            # Cargar ground truth si existe\n",
    "            gt_boxes, gt_labels = self.load_ground_truth(image_file, test_labels_dir)\n",
    "            \n",
    "            # Hacer predicción con ensemble\n",
    "            predictions = self.ensemble.predict(image_path)\n",
    "            \n",
    "            # Calcular métricas para esta imagen\n",
    "            image_metrics = self.calculate_image_metrics(\n",
    "                predictions, gt_boxes, gt_labels, iou_threshold\n",
    "            )\n",
    "            \n",
    "            # Guardar datos de esta imagen\n",
    "            result_data = {\n",
    "                'image_name': image_file,\n",
    "                'predictions_count': len(predictions['boxes']),\n",
    "                'ground_truth_count': len(gt_boxes),\n",
    "                'true_positives': image_metrics['tp'],\n",
    "                'false_positives': image_metrics['fp'],\n",
    "                'false_negatives': image_metrics['fn'],\n",
    "                'precision': image_metrics['precision'],\n",
    "                'recall': image_metrics['recall'],\n",
    "                'f1': image_metrics['f1']\n",
    "            }\n",
    "            results_data.append(result_data)\n",
    "            \n",
    "            # Actualizar métricas globales\n",
    "            self.detection_metrics['true_positives'] += image_metrics['tp']\n",
    "            self.detection_metrics['false_positives'] += image_metrics['fp']\n",
    "            self.detection_metrics['false_negatives'] += image_metrics['fn']\n",
    "            self.detection_metrics['total_predictions'] += len(predictions['boxes'])\n",
    "            self.detection_metrics['total_ground_truth'] += len(gt_boxes)\n",
    "            \n",
    "            # Guardar visualización si se solicita\n",
    "            if save_visualizations:\n",
    "                self.save_visualization(image_path, predictions, gt_boxes, gt_labels, image_file)\n",
    "        \n",
    "        # Calcular métricas finales\n",
    "        final_metrics = self.calculate_final_metrics()\n",
    "        \n",
    "        # Guardar resultados\n",
    "        self.save_results(results_data, final_metrics)\n",
    "        \n",
    "        # Crear gráficos\n",
    "        self.create_plots(results_data, final_metrics)\n",
    "        \n",
    "        print(f\"✅ Evaluación completada. Resultados guardados en: {self.output_dir}\")\n",
    "        \n",
    "        return final_metrics, results_data\n",
    "    \n",
    "    def load_ground_truth(self, image_file, labels_dir):\n",
    "        \"\"\"Cargar ground truth desde archivo YOLO\"\"\"\n",
    "        if labels_dir is None:\n",
    "            return [], []\n",
    "            \n",
    "        label_file = os.path.splitext(image_file)[0] + '.txt'\n",
    "        label_path = os.path.join(labels_dir, label_file)\n",
    "        \n",
    "        boxes = []\n",
    "        labels = []\n",
    "        \n",
    "        if os.path.exists(label_path):\n",
    "            # Obtener dimensiones de imagen para convertir coordenadas\n",
    "            image_path = os.path.join(os.path.dirname(labels_dir), 'images', image_file)\n",
    "            img = cv2.imread(image_path)\n",
    "            if img is not None:\n",
    "                h, w = img.shape[:2]\n",
    "                \n",
    "                with open(label_path, 'r') as f:\n",
    "                    for line in f.readlines():\n",
    "                        parts = line.strip().split()\n",
    "                        if len(parts) >= 5:\n",
    "                            class_id = int(parts[0])\n",
    "                            x_center = float(parts[1]) * w\n",
    "                            y_center = float(parts[2]) * h\n",
    "                            width = float(parts[3]) * w\n",
    "                            height = float(parts[4]) * h\n",
    "                            \n",
    "                            # Convertir a formato xyxy\n",
    "                            x1 = x_center - width / 2\n",
    "                            y1 = y_center - height / 2\n",
    "                            x2 = x_center + width / 2\n",
    "                            y2 = y_center + height / 2\n",
    "                            \n",
    "                            boxes.append([x1, y1, x2, y2])\n",
    "                            labels.append(class_id + 1)  # Convertir a formato Fast-RCNN\n",
    "        \n",
    "        return boxes, labels\n",
    "    \n",
    "    def calculate_image_metrics(self, predictions, gt_boxes, gt_labels, iou_threshold):\n",
    "        \"\"\"Calcula métricas para una imagen individual\"\"\"\n",
    "        tp = 0\n",
    "        fp = 0\n",
    "        fn = 0\n",
    "        \n",
    "        if not predictions['boxes'] and not gt_boxes:\n",
    "            # Imagen sin detecciones ni ground truth\n",
    "            return {'tp': 0, 'fp': 0, 'fn': 0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}\n",
    "        \n",
    "        if not gt_boxes:\n",
    "            # No hay ground truth, todas las predicciones son FP\n",
    "            return {'tp': 0, 'fp': len(predictions['boxes']), 'fn': 0, \n",
    "                   'precision': 0.0, 'recall': 1.0, 'f1': 0.0}\n",
    "        \n",
    "        if not predictions['boxes']:\n",
    "            # No hay predicciones, todos los GT son FN\n",
    "            return {'tp': 0, 'fp': 0, 'fn': len(gt_boxes), \n",
    "                   'precision': 1.0, 'recall': 0.0, 'f1': 0.0}\n",
    "        \n",
    "        # Marcar ground truth como detectados\n",
    "        gt_detected = [False] * len(gt_boxes)\n",
    "        \n",
    "        # Para cada predicción, buscar el mejor match en GT\n",
    "        for pred_box, pred_label in zip(predictions['boxes'], predictions['labels']):\n",
    "            best_iou = 0\n",
    "            best_gt_idx = -1\n",
    "            \n",
    "            for gt_idx, (gt_box, gt_label) in enumerate(zip(gt_boxes, gt_labels)):\n",
    "                if pred_label == gt_label and not gt_detected[gt_idx]:\n",
    "                    iou = self.ensemble.calculate_iou(pred_box, gt_box)\n",
    "                    if iou > best_iou:\n",
    "                        best_iou = iou\n",
    "                        best_gt_idx = gt_idx\n",
    "            \n",
    "            if best_iou >= iou_threshold and best_gt_idx >= 0:\n",
    "                tp += 1\n",
    "                gt_detected[best_gt_idx] = True\n",
    "            else:\n",
    "                fp += 1\n",
    "        \n",
    "        # Contar FN (GT no detectados)\n",
    "        fn = sum(1 for detected in gt_detected if not detected)\n",
    "        \n",
    "        # Calcular métricas\n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "        \n",
    "        return {'tp': tp, 'fp': fp, 'fn': fn, 'precision': precision, 'recall': recall, 'f1': f1}\n",
    "    \n",
    "    def save_visualization(self, image_path, predictions, gt_boxes, gt_labels, image_name):\n",
    "        \"\"\"Guarda imagen con boxes de predicción y ground truth\"\"\"\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            return\n",
    "        \n",
    "        # Copiar imagen para visualización\n",
    "        vis_image = image.copy()\n",
    "        \n",
    "        # Dibujar ground truth en verde\n",
    "        for gt_box, gt_label in zip(gt_boxes, gt_labels):\n",
    "            x1, y1, x2, y2 = map(int, gt_box)\n",
    "            cv2.rectangle(vis_image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(vis_image, f'GT:{gt_label}', (x1, y1-10), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "        \n",
    "        # Dibujar predicciones en rojo\n",
    "        for pred_box, pred_score, pred_label in zip(\n",
    "            predictions['boxes'], predictions['scores'], predictions['labels']\n",
    "        ):\n",
    "            x1, y1, x2, y2 = map(int, pred_box)\n",
    "            cv2.rectangle(vis_image, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "            cv2.putText(vis_image, f'P:{pred_label}({pred_score:.2f})', (x1, y2+15), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "        \n",
    "        # Agregar información en la imagen\n",
    "        info_text = f\"GT: {len(gt_boxes)} | Pred: {len(predictions['boxes'])}\"\n",
    "        cv2.putText(vis_image, info_text, (10, 30), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "        \n",
    "        # Guardar imagen\n",
    "        output_path = os.path.join(self.output_dir, \"visualizations\", f\"result_{image_name}\")\n",
    "        cv2.imwrite(output_path, vis_image)\n",
    "    \n",
    "    def calculate_final_metrics(self):\n",
    "        \"\"\"Calcula métricas finales del conjunto completo\"\"\"\n",
    "        tp = self.detection_metrics['true_positives']\n",
    "        fp = self.detection_metrics['false_positives']\n",
    "        fn = self.detection_metrics['false_negatives']\n",
    "        \n",
    "        # Métricas de detección\n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "        \n",
    "        # Accuracy (para detección de objetos, se calcula diferente)\n",
    "        total_correct = tp\n",
    "        total_samples = tp + fp + fn\n",
    "        accuracy = total_correct / total_samples if total_samples > 0 else 0.0\n",
    "        \n",
    "        final_metrics = {\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1_score': f1,\n",
    "            'accuracy': accuracy,\n",
    "            'true_positives': tp,\n",
    "            'false_positives': fp,\n",
    "            'false_negatives': fn,\n",
    "            'total_predictions': self.detection_metrics['total_predictions'],\n",
    "            'total_ground_truth': self.detection_metrics['total_ground_truth']\n",
    "        }\n",
    "        \n",
    "        return final_metrics\n",
    "    \n",
    "    def save_results(self, results_data, final_metrics):\n",
    "        \"\"\"Guarda resultados en archivos\"\"\"\n",
    "        # Guardar CSV con resultados por imagen\n",
    "        df = pd.DataFrame(results_data)\n",
    "        csv_path = os.path.join(self.output_dir, \"results\", \"detailed_results.csv\")\n",
    "        df.to_csv(csv_path, index=False)\n",
    "        \n",
    "        # Guardar métricas finales\n",
    "        metrics_path = os.path.join(self.output_dir, \"results\", \"final_metrics.txt\")\n",
    "        with open(metrics_path, 'w') as f:\n",
    "            f.write(\"=== MÉTRICAS FINALES DEL ENSEMBLE ===\\n\\n\")\n",
    "            f.write(f\"Precision: {final_metrics['precision']:.4f}\\n\")\n",
    "            f.write(f\"Recall: {final_metrics['recall']:.4f}\\n\")\n",
    "            f.write(f\"F1 Score: {final_metrics['f1_score']:.4f}\\n\")\n",
    "            f.write(f\"Accuracy: {final_metrics['accuracy']:.4f}\\n\\n\")\n",
    "            f.write(\"=== CONTEOS ===\\n\")\n",
    "            f.write(f\"True Positives: {final_metrics['true_positives']}\\n\")\n",
    "            f.write(f\"False Positives: {final_metrics['false_positives']}\\n\")\n",
    "            f.write(f\"False Negatives: {final_metrics['false_negatives']}\\n\")\n",
    "            f.write(f\"Total Predicciones: {final_metrics['total_predictions']}\\n\")\n",
    "            f.write(f\"Total Ground Truth: {final_metrics['total_ground_truth']}\\n\")\n",
    "            f.write(f\"\\nFecha: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "        \n",
    "        print(f\"📊 Resultados guardados en: {csv_path}\")\n",
    "        print(f\"📊 Métricas finales guardadas en: {metrics_path}\")\n",
    "    \n",
    "    def create_plots(self, results_data, final_metrics):\n",
    "        \"\"\"Crea gráficos de resultados\"\"\"\n",
    "        df = pd.DataFrame(results_data)\n",
    "        \n",
    "        # Crear figura con subplots\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "        fig.suptitle('Evaluación del Ensemble - Métricas del Conjunto de Test', fontsize=16)\n",
    "        \n",
    "        # 1. Distribución de métricas por imagen\n",
    "        axes[0, 0].hist(df['precision'], bins=20, alpha=0.7, color='blue', label='Precision')\n",
    "        axes[0, 0].hist(df['recall'], bins=20, alpha=0.7, color='green', label='Recall')\n",
    "        axes[0, 0].hist(df['f1'], bins=20, alpha=0.7, color='red', label='F1')\n",
    "        axes[0, 0].set_title('Distribución de Métricas por Imagen')\n",
    "        axes[0, 0].set_xlabel('Valor de Métrica')\n",
    "        axes[0, 0].set_ylabel('Frecuencia')\n",
    "        axes[0, 0].legend()\n",
    "        \n",
    "        # 2. Número de predicciones vs ground truth\n",
    "        axes[0, 1].scatter(df['ground_truth_count'], df['predictions_count'], alpha=0.6)\n",
    "        axes[0, 1].plot([0, df['ground_truth_count'].max()], [0, df['ground_truth_count'].max()], 'r--')\n",
    "        axes[0, 1].set_title('Predicciones vs Ground Truth')\n",
    "        axes[0, 1].set_xlabel('Ground Truth Count')\n",
    "        axes[0, 1].set_ylabel('Predictions Count')\n",
    "        \n",
    "        # 3. Métricas finales (barras)\n",
    "        metrics_names = ['Precision', 'Recall', 'F1 Score', 'Accuracy']\n",
    "        metrics_values = [\n",
    "            final_metrics['precision'], \n",
    "            final_metrics['recall'], \n",
    "            final_metrics['f1_score'], \n",
    "            final_metrics['accuracy']\n",
    "        ]\n",
    "        bars = axes[0, 2].bar(metrics_names, metrics_values, color=['blue', 'green', 'red', 'orange'])\n",
    "        axes[0, 2].set_title('Métricas Finales del Ensemble')\n",
    "        axes[0, 2].set_ylabel('Valor')\n",
    "        axes[0, 2].set_ylim(0, 1)\n",
    "        \n",
    "        # Agregar valores en las barras\n",
    "        for bar, value in zip(bars, metrics_values):\n",
    "            height = bar.get_height()\n",
    "            axes[0, 2].text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                           f'{value:.3f}', ha='center', va='bottom')\n",
    "        \n",
    "        # 4. Matriz de confusión (simplificada)\n",
    "        tp = final_metrics['true_positives']\n",
    "        fp = final_metrics['false_positives']\n",
    "        fn = final_metrics['false_negatives']\n",
    "        tn = 0  # Para detección de objetos, TN es difícil de definir\n",
    "        \n",
    "        cm = np.array([[tp, fn], [fp, tn]])\n",
    "\n",
    "        cell_labels = [\n",
    "            f'Detectado como Célula\\n(Predicción Positiva)',\n",
    "            f'No Detectado como Célula\\n(Predicción Negativa)'\n",
    "        ]\n",
    "        reality_labels = [\n",
    "            f'Célula Real\\n(Ground Truth Positivo)',\n",
    "            f'Background Real\\n(Ground Truth Negativo)'\n",
    "        ]\n",
    "\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                   xticklabels=cell_labels,\n",
    "                   yticklabels=reality_labels, \n",
    "                   ax=axes[1, 0])\n",
    "        \n",
    "        axes[1, 0].set_title('Matriz de Confusión (Simplificada)')\n",
    "        \n",
    "        # 5. Distribución de TP, FP, FN por imagen\n",
    "        metrics_counts = ['TP', 'FP', 'FN']\n",
    "        tp_counts = df['true_positives'].sum()\n",
    "        fp_counts = df['false_positives'].sum()\n",
    "        fn_counts = df['false_negatives'].sum()\n",
    "        \n",
    "        axes[1, 1].bar(metrics_counts, [tp_counts, fp_counts, fn_counts], \n",
    "                      color=['green', 'red', 'orange'])\n",
    "        axes[1, 1].set_title('Distribución Total de TP, FP, FN')\n",
    "        axes[1, 1].set_ylabel('Cantidad')\n",
    "        \n",
    "        # 6. F1 Score por imagen (ordenado)\n",
    "        df_sorted = df.sort_values('f1', ascending=False)\n",
    "        axes[1, 2].plot(range(len(df_sorted)), df_sorted['f1'], 'b-', alpha=0.7)\n",
    "        axes[1, 2].axhline(y=final_metrics['f1_score'], color='r', linestyle='--', \n",
    "                          label=f'F1 Promedio: {final_metrics[\"f1_score\"]:.3f}')\n",
    "        axes[1, 2].set_title('F1 Score por Imagen (Ordenado)')\n",
    "        axes[1, 2].set_xlabel('Imagen (ordenadas por F1)')\n",
    "        axes[1, 2].set_ylabel('F1 Score')\n",
    "        axes[1, 2].legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Guardar gráficos\n",
    "        plots_path = os.path.join(self.output_dir, \"metrics\", \"evaluation_plots.png\")\n",
    "        plt.savefig(plots_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        print(f\"📈 Gráficos guardados en: {plots_path}\")\n",
    "        \n",
    "        # Crear gráfico adicional: Precisión vs Recall por imagen\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.scatter(df['recall'], df['precision'], alpha=0.6, s=50)\n",
    "        plt.xlabel('Recall')\n",
    "        plt.ylabel('Precision')\n",
    "        plt.title('Precision vs Recall por Imagen')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Agregar punto para métricas promedio\n",
    "        plt.scatter(final_metrics['recall'], final_metrics['precision'], \n",
    "                   color='red', s=100, marker='x', \n",
    "                   label=f'Promedio (P:{final_metrics[\"precision\"]:.3f}, R:{final_metrics[\"recall\"]:.3f})')\n",
    "        plt.legend()\n",
    "        \n",
    "        pr_plot_path = os.path.join(self.output_dir, \"metrics\", \"precision_recall_plot.png\")\n",
    "        plt.savefig(pr_plot_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        print(f\"📈 Gráfico Precision-Recall guardado en: {pr_plot_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f80ea78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Iniciando evaluación del conjunto de test...\n",
      "📁 Directorio de imágenes: ../03.Datasets/YOLO_Datasets/test/images\n",
      "📁 Directorio de salida: ..\\03.Datasets\\Evaluacion_Empresa\\DEFAULT\\Ensemble\n",
      "📊 Total de imágenes a evaluar: 87\n",
      "🔍 Procesando 1/87: 110.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\110.jpg: 1024x1280 1 cell, 97.3ms\n",
      "Speed: 12.9ms preprocess, 97.3ms inference, 4.5ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 9 detecciones\n",
      "YOLO: 1 detecciones\n",
      "Consenso: 0 detecciones\n",
      "🔍 Procesando 2/87: 116.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\116.jpg: 1024x1280 28 cells, 17.0ms\n",
      "Speed: 7.5ms preprocess, 17.0ms inference, 2.2ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 35 detecciones\n",
      "YOLO: 28 detecciones\n",
      "Consenso: 25 detecciones\n",
      "🔍 Procesando 3/87: 124.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\124.jpg: 1024x1280 1 cell, 16.9ms\n",
      "Speed: 8.2ms preprocess, 16.9ms inference, 1.7ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 10 detecciones\n",
      "YOLO: 1 detecciones\n",
      "Consenso: 1 detecciones\n",
      "🔍 Procesando 4/87: 129.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\129.jpg: 1024x1280 1 cell, 16.7ms\n",
      "Speed: 5.8ms preprocess, 16.7ms inference, 1.8ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 5 detecciones\n",
      "YOLO: 1 detecciones\n",
      "Consenso: 0 detecciones\n",
      "🔍 Procesando 5/87: 130.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\130.jpg: 1024x1280 11 cells, 23.2ms\n",
      "Speed: 6.4ms preprocess, 23.2ms inference, 3.7ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 18 detecciones\n",
      "YOLO: 11 detecciones\n",
      "Consenso: 9 detecciones\n",
      "🔍 Procesando 6/87: 134.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\134.jpg: 1024x1280 (no detections), 17.1ms\n",
      "Speed: 6.0ms preprocess, 17.1ms inference, 1.4ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 1 detecciones\n",
      "YOLO: 0 detecciones\n",
      "Consenso: 0 detecciones\n",
      "🔍 Procesando 7/87: 135.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\135.jpg: 1024x1280 11 cells, 17.1ms\n",
      "Speed: 6.4ms preprocess, 17.1ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 22 detecciones\n",
      "YOLO: 11 detecciones\n",
      "Consenso: 11 detecciones\n",
      "🔍 Procesando 8/87: 139.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\139.jpg: 1024x1280 26 cells, 17.1ms\n",
      "Speed: 8.4ms preprocess, 17.1ms inference, 2.3ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 47 detecciones\n",
      "YOLO: 26 detecciones\n",
      "Consenso: 18 detecciones\n",
      "🔍 Procesando 9/87: 142.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\142.jpg: 1024x1280 40 cells, 16.8ms\n",
      "Speed: 6.2ms preprocess, 16.8ms inference, 2.1ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 47 detecciones\n",
      "YOLO: 40 detecciones\n",
      "Consenso: 27 detecciones\n",
      "🔍 Procesando 10/87: 148.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\148.jpg: 1056x1280 4 cells, 77.8ms\n",
      "Speed: 10.9ms preprocess, 77.8ms inference, 3.8ms postprocess per image at shape (1, 3, 1056, 1280)\n",
      "Fast-RCNN: 6 detecciones\n",
      "YOLO: 4 detecciones\n",
      "Consenso: 3 detecciones\n",
      "🔍 Procesando 11/87: 149.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\149.jpg: 1024x1280 9 cells, 18.2ms\n",
      "Speed: 7.8ms preprocess, 18.2ms inference, 2.3ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 21 detecciones\n",
      "YOLO: 9 detecciones\n",
      "Consenso: 9 detecciones\n",
      "🔍 Procesando 12/87: 15.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\15.jpg: 1024x1280 19 cells, 17.3ms\n",
      "Speed: 8.0ms preprocess, 17.3ms inference, 2.5ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 40 detecciones\n",
      "YOLO: 19 detecciones\n",
      "Consenso: 16 detecciones\n",
      "🔍 Procesando 13/87: 162.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\162.jpg: 1024x1280 6 cells, 17.1ms\n",
      "Speed: 5.1ms preprocess, 17.1ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 15 detecciones\n",
      "YOLO: 6 detecciones\n",
      "Consenso: 5 detecciones\n",
      "🔍 Procesando 14/87: 172.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\172.jpg: 1024x1280 4 cells, 16.9ms\n",
      "Speed: 7.4ms preprocess, 16.9ms inference, 1.8ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 12 detecciones\n",
      "YOLO: 4 detecciones\n",
      "Consenso: 4 detecciones\n",
      "🔍 Procesando 15/87: 173.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\173.jpg: 1024x1280 32 cells, 17.4ms\n",
      "Speed: 6.6ms preprocess, 17.4ms inference, 3.4ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 43 detecciones\n",
      "YOLO: 32 detecciones\n",
      "Consenso: 27 detecciones\n",
      "🔍 Procesando 16/87: 174.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\174.jpg: 1024x1280 5 cells, 16.8ms\n",
      "Speed: 5.1ms preprocess, 16.8ms inference, 1.8ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 11 detecciones\n",
      "YOLO: 5 detecciones\n",
      "Consenso: 4 detecciones\n",
      "🔍 Procesando 17/87: 181.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\181.jpg: 1024x1280 6 cells, 16.8ms\n",
      "Speed: 7.6ms preprocess, 16.8ms inference, 2.3ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 15 detecciones\n",
      "YOLO: 6 detecciones\n",
      "Consenso: 3 detecciones\n",
      "🔍 Procesando 18/87: 194.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\194.jpg: 1024x1280 47 cells, 19.5ms\n",
      "Speed: 7.4ms preprocess, 19.5ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 58 detecciones\n",
      "YOLO: 47 detecciones\n",
      "Consenso: 32 detecciones\n",
      "🔍 Procesando 19/87: 211.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\211.jpg: 1024x1280 2 cells, 22.5ms\n",
      "Speed: 5.6ms preprocess, 22.5ms inference, 2.8ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 6 detecciones\n",
      "YOLO: 2 detecciones\n",
      "Consenso: 2 detecciones\n",
      "🔍 Procesando 20/87: 212.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\212.jpg: 1024x1280 13 cells, 25.7ms\n",
      "Speed: 7.9ms preprocess, 25.7ms inference, 2.5ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 18 detecciones\n",
      "YOLO: 13 detecciones\n",
      "Consenso: 10 detecciones\n",
      "🔍 Procesando 21/87: 219.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\219.jpg: 1024x1280 5 cells, 25.4ms\n",
      "Speed: 7.6ms preprocess, 25.4ms inference, 2.7ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 10 detecciones\n",
      "YOLO: 5 detecciones\n",
      "Consenso: 4 detecciones\n",
      "🔍 Procesando 22/87: 220.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\220.jpg: 1024x1280 4 cells, 25.9ms\n",
      "Speed: 6.3ms preprocess, 25.9ms inference, 4.5ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 10 detecciones\n",
      "YOLO: 4 detecciones\n",
      "Consenso: 3 detecciones\n",
      "🔍 Procesando 23/87: 221.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\221.jpg: 1024x1280 23 cells, 25.5ms\n",
      "Speed: 5.6ms preprocess, 25.5ms inference, 2.9ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 49 detecciones\n",
      "YOLO: 23 detecciones\n",
      "Consenso: 18 detecciones\n",
      "🔍 Procesando 24/87: 228.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\228.jpg: 1024x1280 1 cell, 25.6ms\n",
      "Speed: 7.0ms preprocess, 25.6ms inference, 2.9ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 2 detecciones\n",
      "YOLO: 1 detecciones\n",
      "Consenso: 1 detecciones\n",
      "🔍 Procesando 25/87: 229.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\229.jpg: 1024x1280 32 cells, 24.7ms\n",
      "Speed: 7.8ms preprocess, 24.7ms inference, 2.6ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 56 detecciones\n",
      "YOLO: 32 detecciones\n",
      "Consenso: 27 detecciones\n",
      "🔍 Procesando 26/87: 239.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\239.jpg: 1024x1280 8 cells, 26.4ms\n",
      "Speed: 6.5ms preprocess, 26.4ms inference, 2.1ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 14 detecciones\n",
      "YOLO: 8 detecciones\n",
      "Consenso: 8 detecciones\n",
      "🔍 Procesando 27/87: 242.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\242.jpg: 1024x1280 6 cells, 25.4ms\n",
      "Speed: 5.4ms preprocess, 25.4ms inference, 2.5ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 9 detecciones\n",
      "YOLO: 6 detecciones\n",
      "Consenso: 6 detecciones\n",
      "🔍 Procesando 28/87: 244.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\244.jpg: 1024x1280 7 cells, 25.8ms\n",
      "Speed: 7.8ms preprocess, 25.8ms inference, 2.5ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 17 detecciones\n",
      "YOLO: 7 detecciones\n",
      "Consenso: 6 detecciones\n",
      "🔍 Procesando 29/87: 245.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\245.jpg: 1024x1280 7 cells, 25.8ms\n",
      "Speed: 5.5ms preprocess, 25.8ms inference, 3.3ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 20 detecciones\n",
      "YOLO: 7 detecciones\n",
      "Consenso: 4 detecciones\n",
      "🔍 Procesando 30/87: 25.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\25.jpg: 1024x1280 22 cells, 27.6ms\n",
      "Speed: 7.0ms preprocess, 27.6ms inference, 2.1ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 28 detecciones\n",
      "YOLO: 22 detecciones\n",
      "Consenso: 18 detecciones\n",
      "🔍 Procesando 31/87: 273.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\273.jpg: 1024x1280 6 cells, 26.0ms\n",
      "Speed: 5.6ms preprocess, 26.0ms inference, 2.5ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 10 detecciones\n",
      "YOLO: 6 detecciones\n",
      "Consenso: 3 detecciones\n",
      "🔍 Procesando 32/87: 279.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\279.jpg: 1024x1280 16 cells, 24.7ms\n",
      "Speed: 5.8ms preprocess, 24.7ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 24 detecciones\n",
      "YOLO: 16 detecciones\n",
      "Consenso: 12 detecciones\n",
      "🔍 Procesando 33/87: 28.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\28.jpg: 1024x1280 14 cells, 24.6ms\n",
      "Speed: 6.3ms preprocess, 24.6ms inference, 2.1ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 32 detecciones\n",
      "YOLO: 14 detecciones\n",
      "Consenso: 12 detecciones\n",
      "🔍 Procesando 34/87: 296.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\296.jpg: 1024x1280 8 cells, 25.9ms\n",
      "Speed: 8.2ms preprocess, 25.9ms inference, 2.2ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 16 detecciones\n",
      "YOLO: 8 detecciones\n",
      "Consenso: 6 detecciones\n",
      "🔍 Procesando 35/87: 299.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\299.jpg: 1024x1280 4 cells, 25.8ms\n",
      "Speed: 5.1ms preprocess, 25.8ms inference, 2.9ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 12 detecciones\n",
      "YOLO: 4 detecciones\n",
      "Consenso: 3 detecciones\n",
      "🔍 Procesando 36/87: 300.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\300.jpg: 1024x1280 11 cells, 26.1ms\n",
      "Speed: 6.2ms preprocess, 26.1ms inference, 2.4ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 19 detecciones\n",
      "YOLO: 11 detecciones\n",
      "Consenso: 10 detecciones\n",
      "🔍 Procesando 37/87: 301.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\301.jpg: 1024x1280 16 cells, 25.7ms\n",
      "Speed: 8.6ms preprocess, 25.7ms inference, 2.2ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 22 detecciones\n",
      "YOLO: 16 detecciones\n",
      "Consenso: 13 detecciones\n",
      "🔍 Procesando 38/87: 302.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\302.jpg: 1024x1280 7 cells, 25.9ms\n",
      "Speed: 7.3ms preprocess, 25.9ms inference, 2.2ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 13 detecciones\n",
      "YOLO: 7 detecciones\n",
      "Consenso: 6 detecciones\n",
      "🔍 Procesando 39/87: 306.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\306.jpg: 1024x1280 19 cells, 25.1ms\n",
      "Speed: 6.3ms preprocess, 25.1ms inference, 2.4ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 31 detecciones\n",
      "YOLO: 19 detecciones\n",
      "Consenso: 16 detecciones\n",
      "🔍 Procesando 40/87: 307.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\307.jpg: 1024x1280 3 cells, 25.0ms\n",
      "Speed: 7.2ms preprocess, 25.0ms inference, 2.1ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 15 detecciones\n",
      "YOLO: 3 detecciones\n",
      "Consenso: 3 detecciones\n",
      "🔍 Procesando 41/87: 310.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\310.jpg: 1024x1280 5 cells, 25.0ms\n",
      "Speed: 8.9ms preprocess, 25.0ms inference, 4.4ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 9 detecciones\n",
      "YOLO: 5 detecciones\n",
      "Consenso: 4 detecciones\n",
      "🔍 Procesando 42/87: 311.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\311.jpg: 1024x1280 18 cells, 25.1ms\n",
      "Speed: 6.9ms preprocess, 25.1ms inference, 2.1ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 21 detecciones\n",
      "YOLO: 18 detecciones\n",
      "Consenso: 16 detecciones\n",
      "🔍 Procesando 43/87: 320.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\320.jpg: 1056x1280 27 cells, 26.8ms\n",
      "Speed: 7.9ms preprocess, 26.8ms inference, 2.6ms postprocess per image at shape (1, 3, 1056, 1280)\n",
      "Fast-RCNN: 36 detecciones\n",
      "YOLO: 27 detecciones\n",
      "Consenso: 17 detecciones\n",
      "🔍 Procesando 44/87: 321.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\321.jpg: 1024x1280 2 cells, 27.0ms\n",
      "Speed: 5.4ms preprocess, 27.0ms inference, 1.6ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 7 detecciones\n",
      "YOLO: 2 detecciones\n",
      "Consenso: 2 detecciones\n",
      "🔍 Procesando 45/87: 323.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\323.jpg: 1024x1280 8 cells, 25.8ms\n",
      "Speed: 7.9ms preprocess, 25.8ms inference, 2.5ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 10 detecciones\n",
      "YOLO: 8 detecciones\n",
      "Consenso: 6 detecciones\n",
      "🔍 Procesando 46/87: 324.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\324.jpg: 1024x1280 15 cells, 25.4ms\n",
      "Speed: 7.4ms preprocess, 25.4ms inference, 4.4ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 21 detecciones\n",
      "YOLO: 15 detecciones\n",
      "Consenso: 12 detecciones\n",
      "🔍 Procesando 47/87: 33.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\33.jpg: 1024x1280 18 cells, 26.3ms\n",
      "Speed: 5.5ms preprocess, 26.3ms inference, 3.7ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 30 detecciones\n",
      "YOLO: 18 detecciones\n",
      "Consenso: 17 detecciones\n",
      "🔍 Procesando 48/87: 330.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\330.jpg: 1024x1280 11 cells, 25.1ms\n",
      "Speed: 5.8ms preprocess, 25.1ms inference, 4.2ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 17 detecciones\n",
      "YOLO: 11 detecciones\n",
      "Consenso: 9 detecciones\n",
      "🔍 Procesando 49/87: 334.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\334.jpg: 1024x1280 36 cells, 24.7ms\n",
      "Speed: 7.8ms preprocess, 24.7ms inference, 2.5ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 54 detecciones\n",
      "YOLO: 36 detecciones\n",
      "Consenso: 31 detecciones\n",
      "🔍 Procesando 50/87: 344.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\344.jpg: 1056x1280 17 cells, 27.4ms\n",
      "Speed: 7.7ms preprocess, 27.4ms inference, 2.2ms postprocess per image at shape (1, 3, 1056, 1280)\n",
      "Fast-RCNN: 30 detecciones\n",
      "YOLO: 17 detecciones\n",
      "Consenso: 13 detecciones\n",
      "🔍 Procesando 51/87: 346.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\346.jpg: 1024x1280 8 cells, 26.5ms\n",
      "Speed: 7.5ms preprocess, 26.5ms inference, 3.3ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 21 detecciones\n",
      "YOLO: 8 detecciones\n",
      "Consenso: 4 detecciones\n",
      "🔍 Procesando 52/87: 347.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\347.jpg: 1024x1280 14 cells, 25.4ms\n",
      "Speed: 7.1ms preprocess, 25.4ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 24 detecciones\n",
      "YOLO: 14 detecciones\n",
      "Consenso: 12 detecciones\n",
      "🔍 Procesando 53/87: 35.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\35.jpg: 1024x1280 31 cells, 27.0ms\n",
      "Speed: 8.1ms preprocess, 27.0ms inference, 2.6ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 46 detecciones\n",
      "YOLO: 31 detecciones\n",
      "Consenso: 27 detecciones\n",
      "🔍 Procesando 54/87: 360.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\360.jpg: 1024x1280 6 cells, 25.6ms\n",
      "Speed: 6.0ms preprocess, 25.6ms inference, 4.1ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 14 detecciones\n",
      "YOLO: 6 detecciones\n",
      "Consenso: 5 detecciones\n",
      "🔍 Procesando 55/87: 368.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\368.jpg: 1024x1280 31 cells, 24.4ms\n",
      "Speed: 7.7ms preprocess, 24.4ms inference, 2.5ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 42 detecciones\n",
      "YOLO: 31 detecciones\n",
      "Consenso: 22 detecciones\n",
      "🔍 Procesando 56/87: 369.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\369.jpg: 1024x1280 4 cells, 24.9ms\n",
      "Speed: 7.0ms preprocess, 24.9ms inference, 2.4ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 7 detecciones\n",
      "YOLO: 4 detecciones\n",
      "Consenso: 4 detecciones\n",
      "🔍 Procesando 57/87: 371.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\371.jpg: 1024x1280 19 cells, 25.0ms\n",
      "Speed: 7.6ms preprocess, 25.0ms inference, 3.0ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 30 detecciones\n",
      "YOLO: 19 detecciones\n",
      "Consenso: 16 detecciones\n",
      "🔍 Procesando 58/87: 378.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\378.jpg: 1024x1280 4 cells, 26.3ms\n",
      "Speed: 7.4ms preprocess, 26.3ms inference, 2.2ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 19 detecciones\n",
      "YOLO: 4 detecciones\n",
      "Consenso: 2 detecciones\n",
      "🔍 Procesando 59/87: 379.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\379.jpg: 1024x1280 1 cell, 25.9ms\n",
      "Speed: 6.6ms preprocess, 25.9ms inference, 2.4ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 6 detecciones\n",
      "YOLO: 1 detecciones\n",
      "Consenso: 1 detecciones\n",
      "🔍 Procesando 60/87: 38.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\38.jpg: 1024x1280 18 cells, 25.7ms\n",
      "Speed: 5.4ms preprocess, 25.7ms inference, 3.3ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 28 detecciones\n",
      "YOLO: 18 detecciones\n",
      "Consenso: 18 detecciones\n",
      "🔍 Procesando 61/87: 382.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\382.jpg: 1024x1280 2 cells, 25.5ms\n",
      "Speed: 5.4ms preprocess, 25.5ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 7 detecciones\n",
      "YOLO: 2 detecciones\n",
      "Consenso: 2 detecciones\n",
      "🔍 Procesando 62/87: 389.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\389.jpg: 1024x1280 28 cells, 25.9ms\n",
      "Speed: 5.6ms preprocess, 25.9ms inference, 4.0ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 46 detecciones\n",
      "YOLO: 28 detecciones\n",
      "Consenso: 24 detecciones\n",
      "🔍 Procesando 63/87: 392.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\392.jpg: 1024x1280 4 cells, 25.1ms\n",
      "Speed: 5.7ms preprocess, 25.1ms inference, 2.2ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 10 detecciones\n",
      "YOLO: 4 detecciones\n",
      "Consenso: 3 detecciones\n",
      "🔍 Procesando 64/87: 399.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\399.jpg: 1024x1280 (no detections), 25.1ms\n",
      "Speed: 5.4ms preprocess, 25.1ms inference, 1.6ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 7 detecciones\n",
      "YOLO: 0 detecciones\n",
      "Consenso: 0 detecciones\n",
      "🔍 Procesando 65/87: 40.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\40.jpg: 1024x1280 13 cells, 24.9ms\n",
      "Speed: 6.9ms preprocess, 24.9ms inference, 2.4ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 30 detecciones\n",
      "YOLO: 13 detecciones\n",
      "Consenso: 10 detecciones\n",
      "🔍 Procesando 66/87: 415.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\415.jpg: 1024x1280 31 cells, 25.2ms\n",
      "Speed: 5.8ms preprocess, 25.2ms inference, 4.0ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 49 detecciones\n",
      "YOLO: 31 detecciones\n",
      "Consenso: 22 detecciones\n",
      "🔍 Procesando 67/87: 419.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\419.jpg: 1056x1280 1 cell, 26.1ms\n",
      "Speed: 8.2ms preprocess, 26.1ms inference, 1.6ms postprocess per image at shape (1, 3, 1056, 1280)\n",
      "Fast-RCNN: 4 detecciones\n",
      "YOLO: 1 detecciones\n",
      "Consenso: 1 detecciones\n",
      "🔍 Procesando 68/87: 423.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\423.jpg: 1024x1280 25 cells, 26.7ms\n",
      "Speed: 7.0ms preprocess, 26.7ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 31 detecciones\n",
      "YOLO: 25 detecciones\n",
      "Consenso: 22 detecciones\n",
      "🔍 Procesando 69/87: 428.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\428.jpg: 1024x1280 12 cells, 24.7ms\n",
      "Speed: 5.9ms preprocess, 24.7ms inference, 4.0ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 21 detecciones\n",
      "YOLO: 12 detecciones\n",
      "Consenso: 12 detecciones\n",
      "🔍 Procesando 70/87: 445.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\445.jpg: 1024x1280 3 cells, 25.0ms\n",
      "Speed: 8.0ms preprocess, 25.0ms inference, 2.6ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 11 detecciones\n",
      "YOLO: 3 detecciones\n",
      "Consenso: 3 detecciones\n",
      "🔍 Procesando 71/87: 457.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\457.jpg: 1056x1280 3 cells, 26.5ms\n",
      "Speed: 8.3ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 1056, 1280)\n",
      "Fast-RCNN: 6 detecciones\n",
      "YOLO: 3 detecciones\n",
      "Consenso: 3 detecciones\n",
      "🔍 Procesando 72/87: 461.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\461.jpg: 1024x1280 24 cells, 27.0ms\n",
      "Speed: 7.1ms preprocess, 27.0ms inference, 1.9ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 49 detecciones\n",
      "YOLO: 24 detecciones\n",
      "Consenso: 21 detecciones\n",
      "🔍 Procesando 73/87: 465.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\465.jpg: 1024x1280 4 cells, 26.1ms\n",
      "Speed: 8.8ms preprocess, 26.1ms inference, 2.7ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 13 detecciones\n",
      "YOLO: 4 detecciones\n",
      "Consenso: 3 detecciones\n",
      "🔍 Procesando 74/87: 466.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\466.jpg: 1024x1280 7 cells, 25.7ms\n",
      "Speed: 7.2ms preprocess, 25.7ms inference, 2.4ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 19 detecciones\n",
      "YOLO: 7 detecciones\n",
      "Consenso: 6 detecciones\n",
      "🔍 Procesando 75/87: 51.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\51.jpg: 1024x1280 46 cells, 27.0ms\n",
      "Speed: 7.4ms preprocess, 27.0ms inference, 5.1ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 53 detecciones\n",
      "YOLO: 46 detecciones\n",
      "Consenso: 40 detecciones\n",
      "🔍 Procesando 76/87: 57.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\57.jpg: 1024x1280 19 cells, 26.8ms\n",
      "Speed: 6.1ms preprocess, 26.8ms inference, 4.1ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 31 detecciones\n",
      "YOLO: 19 detecciones\n",
      "Consenso: 18 detecciones\n",
      "🔍 Procesando 77/87: 59.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\59.jpg: 1024x1280 36 cells, 24.3ms\n",
      "Speed: 7.0ms preprocess, 24.3ms inference, 2.1ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 60 detecciones\n",
      "YOLO: 36 detecciones\n",
      "Consenso: 27 detecciones\n",
      "🔍 Procesando 78/87: 61.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\61.jpg: 1024x1280 39 cells, 25.5ms\n",
      "Speed: 7.6ms preprocess, 25.5ms inference, 4.3ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 57 detecciones\n",
      "YOLO: 39 detecciones\n",
      "Consenso: 34 detecciones\n",
      "🔍 Procesando 79/87: 62.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\62.jpg: 1024x1280 6 cells, 27.2ms\n",
      "Speed: 5.9ms preprocess, 27.2ms inference, 2.8ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 12 detecciones\n",
      "YOLO: 6 detecciones\n",
      "Consenso: 5 detecciones\n",
      "🔍 Procesando 80/87: 63.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\63.jpg: 1024x1280 31 cells, 24.9ms\n",
      "Speed: 7.1ms preprocess, 24.9ms inference, 4.4ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 42 detecciones\n",
      "YOLO: 31 detecciones\n",
      "Consenso: 29 detecciones\n",
      "🔍 Procesando 81/87: 7.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\7.jpg: 1024x1280 21 cells, 28.7ms\n",
      "Speed: 6.1ms preprocess, 28.7ms inference, 3.6ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 37 detecciones\n",
      "YOLO: 21 detecciones\n",
      "Consenso: 19 detecciones\n",
      "🔍 Procesando 82/87: 73.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\73.jpg: 1024x1280 20 cells, 25.4ms\n",
      "Speed: 7.0ms preprocess, 25.4ms inference, 2.2ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 27 detecciones\n",
      "YOLO: 20 detecciones\n",
      "Consenso: 19 detecciones\n",
      "🔍 Procesando 83/87: 79.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\79.jpg: 1024x1280 (no detections), 28.3ms\n",
      "Speed: 8.7ms preprocess, 28.3ms inference, 1.5ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 17 detecciones\n",
      "YOLO: 0 detecciones\n",
      "Consenso: 0 detecciones\n",
      "🔍 Procesando 84/87: 8.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\8.jpg: 1024x1280 21 cells, 28.0ms\n",
      "Speed: 8.9ms preprocess, 28.0ms inference, 4.4ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 35 detecciones\n",
      "YOLO: 21 detecciones\n",
      "Consenso: 17 detecciones\n",
      "🔍 Procesando 85/87: 87.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\87.jpg: 1024x1280 8 cells, 25.1ms\n",
      "Speed: 7.5ms preprocess, 25.1ms inference, 4.5ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 15 detecciones\n",
      "YOLO: 8 detecciones\n",
      "Consenso: 8 detecciones\n",
      "🔍 Procesando 86/87: 9.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\9.jpg: 1024x1280 9 cells, 25.5ms\n",
      "Speed: 5.8ms preprocess, 25.5ms inference, 2.7ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 27 detecciones\n",
      "YOLO: 9 detecciones\n",
      "Consenso: 8 detecciones\n",
      "🔍 Procesando 87/87: 95.jpg\n",
      "\n",
      "image 1/1 c:\\Users\\mini7\\Desktop\\Master\\Materias\\TFM\\Laura\\2025_MURIA_Aitor Garca Blanco\\04.Codigo\\..\\03.Datasets\\YOLO_Datasets\\test\\images\\95.jpg: 1024x1280 14 cells, 24.5ms\n",
      "Speed: 7.2ms preprocess, 24.5ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "Fast-RCNN: 20 detecciones\n",
      "YOLO: 14 detecciones\n",
      "Consenso: 12 detecciones\n",
      "📊 Resultados guardados en: ..\\03.Datasets\\Evaluacion_Empresa\\DEFAULT\\Ensemble\\results\\detailed_results.csv\n",
      "📊 Métricas finales guardadas en: ..\\03.Datasets\\Evaluacion_Empresa\\DEFAULT\\Ensemble\\results\\final_metrics.txt\n",
      "📈 Gráficos guardados en: ..\\03.Datasets\\Evaluacion_Empresa\\DEFAULT\\Ensemble\\metrics\\evaluation_plots.png\n",
      "📈 Gráfico Precision-Recall guardado en: ..\\03.Datasets\\Evaluacion_Empresa\\DEFAULT\\Ensemble\\metrics\\precision_recall_plot.png\n",
      "✅ Evaluación completada. Resultados guardados en: ..\\03.Datasets\\Evaluacion_Empresa\\DEFAULT\\Ensemble\n",
      "\n",
      "==================================================\n",
      "🎯 RESULTADOS FINALES DEL ENSEMBLE\n",
      "==================================================\n",
      "Precision: 0.9152\n",
      "Recall: 0.7125\n",
      "F1 Score: 0.8012\n",
      "Accuracy: 0.6684\n",
      "\n",
      "True Positives: 907\n",
      "False Positives: 84 ⬅️ REDUCIDOS\n",
      "False Negatives: 366\n",
      "\n",
      "Total Predicciones: 991\n",
      "Total Ground Truth: 1273\n"
     ]
    }
   ],
   "source": [
    "# Crear el ensemble\n",
    "consensus_ensemble = ConsensusEnsemble(\n",
    "    fast_rcnn_path=\"./Fast_RCNN_models/best_model.pth\",\n",
    "    yolo_path=\"./runs/detect/yolov11ny_new/weights/best.pt\",\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    ")\n",
    "\n",
    "# Configurar parámetros conservadores\n",
    "consensus_ensemble.consensus_iou_threshold = 0.5\n",
    "consensus_ensemble.min_confidence = 0.7\n",
    "\n",
    "# Crear evaluador\n",
    "evaluator = ConsensusEnsembleEvaluator(\n",
    "    consensus_ensemble=consensus_ensemble,\n",
    "    output_dir=\"..\\\\03.Datasets\\\\Evaluacion_Empresa\\\\DEFAULT\\\\Ensemble\"\n",
    ")\n",
    "\n",
    "# Evaluar conjunto de test completo\n",
    "final_metrics, detailed_results = evaluator.evaluate_test_set(\n",
    "    test_images_dir=\"../03.Datasets/YOLO_Datasets/test/images\",\n",
    "    test_labels_dir=\"../03.Datasets/YOLO_Datasets/test/labels\",\n",
    "    iou_threshold=0.5,\n",
    "    save_visualizations=True\n",
    ")\n",
    "\n",
    "# Mostrar resultados finales\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"🎯 RESULTADOS FINALES DEL ENSEMBLE\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Precision: {final_metrics['precision']:.4f}\")\n",
    "print(f\"Recall: {final_metrics['recall']:.4f}\")\n",
    "print(f\"F1 Score: {final_metrics['f1_score']:.4f}\")\n",
    "print(f\"Accuracy: {final_metrics['accuracy']:.4f}\")\n",
    "print(f\"\\nTrue Positives: {final_metrics['true_positives']}\")\n",
    "print(f\"False Positives: {final_metrics['false_positives']}\")\n",
    "print(f\"False Negatives: {final_metrics['false_negatives']}\")\n",
    "print(f\"\\nTotal Predicciones: {final_metrics['total_predictions']}\")\n",
    "print(f\"Total Ground Truth: {final_metrics['total_ground_truth']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TFM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
